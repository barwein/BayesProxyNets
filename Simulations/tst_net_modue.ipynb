{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.scipy.special import logit\n",
    "import numpy as np\n",
    "\n",
    "from Simulations.simulation_aux import one_simulation_iter\n",
    "import Simulations.data_gen as dg\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "import src.Models as models\n",
    "import src.utils as utils\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.contrib.funsor import config_enumerate\n",
    "\n",
    "\n",
    "# --- Set cores and seed ---\n",
    "N_CORES = 4\n",
    "os.environ[\"XLA_FLAGS\"] = f\"--xla_force_host_platform_device_count={N_CORES}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 500\n",
    "# N = 1000\n",
    "TRIU_DIM = N * (N - 1) // 2\n",
    "\n",
    "THETA = jnp.array([-2.5, 1])\n",
    "# GAMMA_FIX = jnp.array([logit(0.9), logit(0.1), 1])\n",
    "# GAMMA_FIX = jnp.array([logit(0.85), logit(0.15)])\n",
    "# GAMMA_X_NOISES = jnp.arange(0.2, 2.2, 0.2)\n",
    "# GAMMA_X_NOISES = jnp.arange(0, 1.1, 0.1)\n",
    "GAMMA = jnp.array([logit(0.9), logit(0.1), 0.5])\n",
    "\n",
    "ETA = jnp.array([-1, 3, -0.25, 2])\n",
    "SIG_INV = 2 / 3\n",
    "RHO = 0.5\n",
    "PZ = 0.5\n",
    "\n",
    "PARAM = {\n",
    "    \"theta\": THETA,\n",
    "    \"eta\": ETA,\n",
    "    \"rho\": RHO,\n",
    "    \"sig_inv\": SIG_INV,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(55)\n",
    "rng = np.random.default_rng(22)\n",
    "\n",
    "fixed_data = dg.generate_fixed_data(rng, N, PARAM, PZ)\n",
    "\n",
    "new_interventions = dg.new_interventions_estimands(\n",
    "        rng, N, fixed_data[\"x\"], fixed_data[\"triu_star\"], ETA\n",
    "    )\n",
    "\n",
    "proxy_nets = dg.generate_proxy_networks(\n",
    "        rng,\n",
    "        TRIU_DIM,\n",
    "        fixed_data[\"triu_star\"],\n",
    "        GAMMA,\n",
    "        fixed_data[\"x_diff\"],\n",
    "        fixed_data[\"Z\"],\n",
    "    )\n",
    "\n",
    "data_sim = dg.data_for_sim(fixed_data, proxy_nets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([103459.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,  21291.]),\n",
       " array([-2.5       , -2.4000001 , -2.29999995, -2.20000005, -2.0999999 ,\n",
       "        -2.        , -1.89999998, -1.79999995, -1.70000005, -1.60000002,\n",
       "        -1.5       ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(THETA[0] + THETA[1]*data_sim.x2_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "def network_only_models_marginalized(data):\n",
    "    \"\"\"\n",
    "    Bayesian network model with marginalized latent network A*.\n",
    "\n",
    "    Args:\n",
    "      data: an object with attributes:\n",
    "         - x_diff: difference in covariate values per edge (e.g., shape [num_edges])\n",
    "         - x2_or: indicator if x2_i + x2_j = 1 (shape [num_edges])\n",
    "         - triu_obs: observed upper-triangular adjacency matrix values (binary, shape [num_edges])\n",
    "    \"\"\"\n",
    "    # --- Priors on continuous parameters ---\n",
    "    # Using vectorized sample statements for theta (2 parameters) and gamma (3 parameters)\n",
    "    theta = numpyro.sample(\"theta\", dist.Normal(0, 5).expand([2]))\n",
    "    gamma = numpyro.sample(\"gamma\", dist.Normal(0, 5).expand([3]))\n",
    "\n",
    "    # --- Latent network (A*) prior ---\n",
    "    # Logits for edge probability of A* = 1 (for each edge)\n",
    "    star_logits = theta[0] + theta[1] * data.x2_or\n",
    "    star_logits = jnp.clip(star_logits, -20, 20)  # for numerical stability\n",
    "\n",
    "    # Instead of using x - log1p(exp(x)), we use the stable softplus:\n",
    "    # log(sigmoid(x)) = -log(1 + exp(-x)) = x - softplus(x)\n",
    "    # log(1-sigmoid(x)) = -softplus(x)\n",
    "    log_nu_1 = star_logits - jax.nn.softplus(star_logits)  # log probability for A* = 1\n",
    "    log_nu_0 = - jax.nn.softplus(star_logits)              # log probability for A* = 0\n",
    "\n",
    "    # --- Likelihood for the observed network A given A* ---\n",
    "    # For edges with A* = 1 we use parameter gamma[0], and for A* = 0 we use a logistic regression\n",
    "    # with linear predictor obs_logits_k0.\n",
    "    obs_logits_k0 = gamma[1] + gamma[2] * data.x_diff\n",
    "    obs_logits_k0 = jnp.clip(obs_logits_k0, -20, 20)  # for numerical stability\n",
    "\n",
    "    # The typical Bernoulli log-likelihood for an observation y given logit ℓ is:\n",
    "    #   y * ℓ - softplus(ℓ)\n",
    "    log_xi_1 = data.triu_obs * gamma[0] - jax.nn.softplus(gamma[0])\n",
    "    log_xi_0 = data.triu_obs * obs_logits_k0 - jax.nn.softplus(obs_logits_k0)\n",
    "\n",
    "    # --- Marginalizing over A* ---\n",
    "    # For each edge we have two terms (A* = 1 and A* = 0). Write the joint log-probability\n",
    "    # for each possibility:\n",
    "    log_joint_1 = log_nu_1 + log_xi_1\n",
    "    log_joint_0 = log_nu_0 + log_xi_0\n",
    "\n",
    "    # Now marginalize: for each edge compute\n",
    "    # log( xi * nu ) = logaddexp( log_joint_1, log_joint_0 )\n",
    "    log_marginal = jnp.logaddexp(log_joint_1, log_joint_0)\n",
    "\n",
    "    # It is often a good idea to use plates over independent observations.\n",
    "    # Assuming each edge is independent, we can write:\n",
    "    with numpyro.plate(\"edges\", data.triu_obs.shape[0]):\n",
    "        # Here we add the contribution for each edge; if you prefer, you can use a dummy observation:\n",
    "        numpyro.factor(\"marginalized_likelihood\", log_marginal)\n",
    "\n",
    "    # --- Optional: Compute posterior probabilities for A* (for post-processing) ---\n",
    "    # p(A* = 1 | data, theta, gamma) = exp( log_joint_1 - log_marginal )\n",
    "    astar_probs = jnp.exp(log_joint_1 - log_marginal)\n",
    "    numpyro.deterministic(\"astar_probs\", astar_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def network_mixture_model(data):\n",
    "    \"\"\"\n",
    "    Model that embeds the likelihood in a mixture distribution.\n",
    "\n",
    "    Args:\n",
    "      data: an object with attributes:\n",
    "           - x_diff: a 1D array (one per edge) of differences in covariates,\n",
    "           - x2_or: a 1D array of indicators (one per edge) for whether x2_i + x2_j = 1,\n",
    "           - triu_obs: a 1D array of observed edge indicators (binary; one per edge).\n",
    "    \"\"\"\n",
    "    # --- Priors ---\n",
    "    # theta: parameters for the latent network A*\n",
    "    theta = numpyro.sample(\"theta\", dist.Normal(0, 5).expand([2]))\n",
    "    # gamma: parameters for the edge likelihood given A*\n",
    "    gamma = numpyro.sample(\"gamma\", dist.Normal(0, 5).expand([3]))\n",
    "\n",
    "    # --- Latent network A* prior embedded in the mixture weights ---\n",
    "    # Compute the logits for the latent A* for each edge.\n",
    "    star_logits = theta[0] + theta[1] * data.x2_or\n",
    "    star_logits = jnp.clip(star_logits, -20, 20)  # avoid overflow\n",
    "    # Prior probability for A* = 1:\n",
    "    prior_Astar_1 = jax.nn.sigmoid(star_logits)\n",
    "    # Mixture probabilities: first component corresponds to A* = 0, second to A* = 1.\n",
    "    mix_probs = jnp.stack([1 - prior_Astar_1, prior_Astar_1], axis=-1)\n",
    "\n",
    "    # # The probability that A* = 1 is sigmoid(star_logits)\n",
    "    # # Create a 2-element vector of mixture weights for each edge:\n",
    "    # # component 0 (A* = 0) gets weight 1 - sigmoid(star_logits)\n",
    "    # # component 1 (A* = 1) gets weight sigmoid(star_logits)\n",
    "    # mix_probs = jnp.stack([1 - jax.nn.sigmoid(star_logits),\n",
    "    #                        jax.nn.sigmoid(star_logits)], axis=-1)\n",
    "\n",
    "    # --- Likelihood for A given A* ---\n",
    "    # When A* = 0, we use a logistic regression with linear predictor:\n",
    "    obs_logits_k0 = gamma[1] + gamma[2] * data.x_diff\n",
    "    obs_logits_k0 = jnp.clip(obs_logits_k0, -20, 20)  # avoid overflow\n",
    "\n",
    "    # When A* = 1, the likelihood is given by a fixed Bernoulli with logit gamma[0].\n",
    "    comp_logits = jnp.stack([obs_logits_k0,\n",
    "                             gamma[0] * jnp.ones_like(obs_logits_k0)], axis=-1)\n",
    "\n",
    "    # --- Define the mixture distribution ---\n",
    "    # The mixture is over two Bernoulli components.\n",
    "    mixture_dist = dist.MixtureSameFamily(\n",
    "        # The categorical mixing distribution with probabilities given per edge.\n",
    "        mixing_distribution=dist.Categorical(probs=mix_probs),\n",
    "        # The two components: Bernoulli with logits defined in comp_logits.\n",
    "        component_distribution=dist.Bernoulli(logits=comp_logits)\n",
    "    )\n",
    "\n",
    "    # --- Observation ---\n",
    "    # Each edge is conditionally independent.\n",
    "    with numpyro.plate(\"edges\", data.triu_obs.shape[0]):\n",
    "        numpyro.sample(\"obs\", mixture_dist, obs=data.triu_obs)\n",
    "\n",
    "    # --- Compute the posterior probabilities for A* ---\n",
    "    # Compute the log-likelihoods for each component for each edge.\n",
    "    # For component 0 (A* = 0):\n",
    "    log_lik_0 = data.triu_obs * obs_logits_k0 - jax.nn.softplus(obs_logits_k0)\n",
    "    # For component 1 (A* = 1):\n",
    "    log_lik_1 = data.triu_obs * gamma[0] - jax.nn.softplus(gamma[0])\n",
    "    \n",
    "    # Incorporate the log prior probabilities:\n",
    "    log_prior_0 = jnp.log(1 - prior_Astar_1)\n",
    "    log_prior_1 = jnp.log(prior_Astar_1)\n",
    "    \n",
    "    log_joint_0 = log_prior_0 + log_lik_0\n",
    "    log_joint_1 = log_prior_1 + log_lik_1\n",
    "    \n",
    "    # Normalizing constant per edge:\n",
    "    log_norm = jnp.logaddexp(log_joint_0, log_joint_1)\n",
    "    # Posterior probability for A* = 1:\n",
    "    astar_probs = jnp.exp(log_joint_1 - log_norm)\n",
    "    \n",
    "    # Return as a deterministic output (for each edge)\n",
    "    numpyro.deterministic(\"triu_star_probs\", astar_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [03:49<00:00, 65.30it/s, init loss: 113912.7188, avg. loss [14251-15000]: 67634.0921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True theta: [-2.5  1. ] \n",
      " Estimated theta: [-2.4016962  0.9181367] \n",
      " True gamma: [ 2.1972244 -2.1972246  0.5      ] \n",
      " Estimated gamma: [ 1.9317814  -2.196155    0.49599525] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, TraceGraph_ELBO\n",
    "from numpyro.optim import ClippedAdam\n",
    "from numpyro.infer.autoguide import AutoDelta, AutoLowRankMultivariateNormal, AutoNormal, AutoDAIS\n",
    "\n",
    "# --- Compile the model ---\n",
    "\n",
    "# guide = AutoDelta(network_only_models_marginalized)\n",
    "# guide = AutoDAIS(network_mixture_model)\n",
    "guide = AutoDelta(network_mixture_model)\n",
    "# guide = AutoNormal(network_mixture_model)\n",
    "# guide = AutoNormal(network_only_models_marginalized,\n",
    "                #    init_loc_fn=numpyro.infer.init_to_median)\n",
    "\n",
    "svi_ = SVI(\n",
    "    # model=network_only_models_marginalized,\n",
    "    model=network_mixture_model,\n",
    "    guide=guide,\n",
    "    optim=ClippedAdam(0.001),\n",
    "    loss=Trace_ELBO(),\n",
    "    # loss=TraceGraph_ELBO(),\n",
    ")\n",
    "\n",
    "svi_results = svi_.run(random.split(rng_key)[0], 15000, data_sim)\n",
    "\n",
    "map_params = guide.median(svi_results.params)\n",
    "\n",
    "print(\"True theta:\", THETA, \"\\n\",\n",
    "      \"Estimated theta:\", map_params[\"theta\"], \"\\n\",\n",
    "      \"True gamma:\", GAMMA, \"\\n\",\n",
    "      \"Estimated gamma:\", map_params[\"gamma\"], \"\\n\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIU_DIM = N * (N - 1) // 2\n",
    "\n",
    "@config_enumerate  # This enables automatic enumeration of discrete latent variables.\n",
    "def model_enumerated(data):\n",
    "    \"\"\"\n",
    "    Model with explicit enumeration of discrete latent variable A*.\n",
    "    \n",
    "    Args:\n",
    "        data: An object with attributes:\n",
    "              - x_diff: (num_edges,) covariate differences per edge.\n",
    "              - x2_or: (num_edges,) indicator for x2_i + x2_j == 1.\n",
    "              - triu_obs: (num_edges,) observed binary outcomes.\n",
    "              - num_edges: integer number of edges.\n",
    "    \"\"\"\n",
    "    # Priors for continuous parameters.\n",
    "    with numpyro.plate(\"theta_plate\", 2):\n",
    "        theta = numpyro.sample(\"theta\", dist.Normal(0, 3))\n",
    "\n",
    "    with numpyro.plate(\"gamma_plate\", 3):\n",
    "        gamma = numpyro.sample(\"gamma\", dist.Normal(0, 3))\n",
    "    # theta = numpyro.sample(\"theta\", dist.Normal(0, 3).expand([2]))\n",
    "    # gamma = numpyro.sample(\"gamma\", dist.Normal(0, 3).expand([3]))\n",
    "\n",
    "\n",
    "    # Compute logits for the latent variable A*\n",
    "    star_logits = theta[0] + theta[1] * data.x2_or\n",
    "\n",
    "    # Use a plate to vectorize over edges.\n",
    "    with numpyro.plate(\"triu_vals\", size=TRIU_DIM):\n",
    "        # Sample A_star (latent binary variable) and enumerate it.\n",
    "        A_star = numpyro.sample(\n",
    "            \"A_star\",\n",
    "            dist.Bernoulli(logits=star_logits),\n",
    "            infer={'enumerate': 'parallel'}  # Enables automatic marginalization.\n",
    "        )\n",
    "\n",
    "        # Define the observation likelihood:\n",
    "        # If A_star == 1: use gamma[0] (true positives)\n",
    "        # If A_star == 0: use gamma[1] + gamma[2] * x_diff (false positives)\n",
    "        obs_logits = jnp.where(A_star, gamma[0], gamma[1] + gamma[2] * data.x_diff)\n",
    "\n",
    "        # Observations\n",
    "        numpyro.sample(\"obs\", dist.Bernoulli(logits=obs_logits), obs=data.triu_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Assume data_sim is your data object with the required attributes.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m rng_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m svi_result \u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_sim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# You can extract the learned parameters and monitor the ELBO:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m params \u001b[38;5;241m=\u001b[39m svi_result\u001b[38;5;241m.\u001b[39mparams\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\infer\\svi.py:401\u001b[0m, in \u001b[0;36mSVI.run\u001b[1;34m(self, rng_key, num_steps, progress_bar, stable_update, forward_mode_differentiation, init_state, init_params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m svi_state, loss\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     svi_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     svi_state \u001b[38;5;241m=\u001b[39m init_state\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\infer\\svi.py:184\u001b[0m, in \u001b[0;36mSVI.init\u001b[1;34m(self, rng_key, init_params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     guide_init \u001b[38;5;241m=\u001b[39m substitute(guide_init, init_params)\n\u001b[1;32m--> 184\u001b[0m guide_trace \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mguide_init\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatic_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m init_guide_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    186\u001b[0m     name: site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, site \u001b[38;5;129;01min\u001b[39;00m guide_trace\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m }\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\handlers.py:186\u001b[0m, in \u001b[0;36mtrace.get_trace\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Run the wrapped callable and return the recorded trace.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    :return: `OrderedDict` containing the execution trace.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\infer\\autoguide.py:706\u001b[0m, in \u001b[0;36mAutoContinuous.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototype_trace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;66;03m# run model to inspect the model structure\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_prototype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_latent(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;66;03m# unpack continuous latent samples\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\infer\\autoguide.py:666\u001b[0m, in \u001b[0;36mAutoContinuous._setup_prototype\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_prototype\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_prototype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_latent, shape_dict \u001b[38;5;241m=\u001b[39m _ravel_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_locs)\n\u001b[0;32m    668\u001b[0m     unpack_latent \u001b[38;5;241m=\u001b[39m partial(_unravel_dict, shape_dict\u001b[38;5;241m=\u001b[39mshape_dict)\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\infer\\autoguide.py:158\u001b[0m, in \u001b[0;36mAutoGuide._setup_prototype\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m rng_key \u001b[38;5;241m=\u001b[39m numpyro\u001b[38;5;241m.\u001b[39mprng_key()\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m handlers\u001b[38;5;241m.\u001b[39mblock():\n\u001b[0;32m    153\u001b[0m     (\n\u001b[0;32m    154\u001b[0m         init_params,\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_potential_fn_gen,\n\u001b[0;32m    156\u001b[0m         postprocess_fn_gen,\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototype_trace,\n\u001b[1;32m--> 158\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_loc_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_potential_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_potential_fn_gen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m postprocess_fn \u001b[38;5;241m=\u001b[39m postprocess_fn_gen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\infer\\util.py:663\u001b[0m, in \u001b[0;36minitialize_model\u001b[1;34m(rng_key, model, init_strategy, dynamic_args, model_args, model_kwargs, forward_mode_differentiation, validate_grad)\u001b[0m\n\u001b[0;32m    653\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_kwargs\n\u001b[0;32m    654\u001b[0m substituted_model \u001b[38;5;241m=\u001b[39m substitute(\n\u001b[0;32m    655\u001b[0m     seed(model, rng_key \u001b[38;5;28;01mif\u001b[39;00m is_prng_key(rng_key) \u001b[38;5;28;01melse\u001b[39;00m rng_key[\u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m    656\u001b[0m     substitute_fn\u001b[38;5;241m=\u001b[39minit_strategy,\n\u001b[0;32m    657\u001b[0m )\n\u001b[0;32m    658\u001b[0m (\n\u001b[0;32m    659\u001b[0m     inv_transforms,\n\u001b[0;32m    660\u001b[0m     replay_model,\n\u001b[0;32m    661\u001b[0m     has_enumerate_support,\n\u001b[0;32m    662\u001b[0m     model_trace,\n\u001b[1;32m--> 663\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstituted_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;66;03m# substitute param sites from model_trace to model so\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;66;03m# we don't need to generate again parameters of `numpyro.module`\u001b[39;00m\n\u001b[0;32m    666\u001b[0m model \u001b[38;5;241m=\u001b[39m substitute(\n\u001b[0;32m    667\u001b[0m     model,\n\u001b[0;32m    668\u001b[0m     data\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    672\u001b[0m     },\n\u001b[0;32m    673\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\infer\\util.py:457\u001b[0m, in \u001b[0;36m_get_model_transforms\u001b[1;34m(model, model_args, model_kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_transforms\u001b[39m(model, model_args\u001b[38;5;241m=\u001b[39m(), model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    456\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_kwargs\n\u001b[1;32m--> 457\u001b[0m     model_trace \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m     inv_transforms \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# model code may need to be replayed in the presence of deterministic sites\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\handlers.py:186\u001b[0m, in \u001b[0;36mtrace.get_trace\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Run the wrapped callable and return the recorded trace.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    :return: `OrderedDict` containing the execution trace.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: Messenger.__call__ at line 105 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 31\u001b[0m, in \u001b[0;36mmodel_enumerated\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Use a plate to vectorize over edges.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m numpyro\u001b[38;5;241m.\u001b[39mplate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriu_vals\u001b[39m\u001b[38;5;124m\"\u001b[39m, size\u001b[38;5;241m=\u001b[39mTRIU_DIM):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Sample A_star (latent binary variable) and enumerate it.\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     A_star \u001b[38;5;241m=\u001b[39m \u001b[43mnumpyro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA_star\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBernoulli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstar_logits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menumerate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparallel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Enables automatic marginalization.\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Define the observation likelihood:\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# If A_star == 1: use gamma[0] (true positives)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# If A_star == 0: use gamma[1] + gamma[2] * x_diff (false positives)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     obs_logits \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mwhere(A_star, gamma[\u001b[38;5;241m0\u001b[39m], gamma[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m gamma[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39mx_diff)\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\primitives.py:222\u001b[0m, in \u001b[0;36msample\u001b[1;34m(name, fn, obs, rng_key, sample_shape, infer, obs_mask)\u001b[0m\n\u001b[0;32m    207\u001b[0m initial_msg \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m\"\u001b[39m: {} \u001b[38;5;28;01mif\u001b[39;00m infer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m infer,\n\u001b[0;32m    219\u001b[0m }\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# ...and use apply_stack to send it to the Messengers\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[43mapply_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\primitives.py:53\u001b[0m, in \u001b[0;36mapply_stack\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[43mdefault_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# A Messenger that sets msg[\"stop\"] == True also prevents application\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# of postprocess_message by Messengers above it on the stack\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# via the pointer variable from the process_message loop\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m _PYRO_STACK[\u001b[38;5;241m-\u001b[39mpointer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m :]:\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\primitives.py:24\u001b[0m, in \u001b[0;36mdefault_process_message\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 24\u001b[0m         msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m], msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediates\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m         msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m\"\u001b[39m](\u001b[38;5;241m*\u001b[39mmsg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\distributions\\distribution.py:388\u001b[0m, in \u001b[0;36mDistribution.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m sample_intermediates \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_intermediates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_intermediates:\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_with_intermediates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(key, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\distributions\\distribution.py:346\u001b[0m, in \u001b[0;36mDistribution.sample_with_intermediates\u001b[1;34m(self, key, sample_shape)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_with_intermediates\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, sample_shape\u001b[38;5;241m=\u001b[39m()):\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    Same as ``sample`` except that any intermediate computations are\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    returned (useful for `TransformedDistribution`).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m    :rtype: numpy.ndarray\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m, []\n",
      "File \u001b[1;32mc:\\Users\\bar21\\.conda\\envs\\STAT\\Lib\\site-packages\\numpyro\\distributions\\discrete.py:131\u001b[0m, in \u001b[0;36mBernoulliLogits.sample\u001b[1;34m(self, key, sample_shape)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, sample_shape\u001b[38;5;241m=\u001b[39m()):\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_prng_key(key)\n\u001b[0;32m    132\u001b[0m     samples \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mbernoulli(\n\u001b[0;32m    133\u001b[0m         key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs, shape\u001b[38;5;241m=\u001b[39msample_shape \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m    134\u001b[0m     )\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m samples\u001b[38;5;241m.\u001b[39mastype(jnp\u001b[38;5;241m.\u001b[39mresult_type(samples, \u001b[38;5;28mint\u001b[39m))\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numpyro.infer import SVI, TraceEnum_ELBO\n",
    "from numpyro.optim import ClippedAdam\n",
    "from numpyro.infer.autoguide import AutoDelta, AutoLowRankMultivariateNormal\n",
    "# from numpyro.infer.initialization import init_to_value\n",
    "import numpyro.handlers as handlers\n",
    "\n",
    "import jax\n",
    "\n",
    "# def guide_map(data):\n",
    "#     # with handlers.block(model_enumerated, hide=[\"A_star\"]):  # Ignore discrete latent variable\n",
    "#         # return AutoDelta(model_enumerated)(data)\n",
    "#     block_model = handlers.block(model_enumerated, hide=[\"A_star\"])\n",
    "#     return AutoDelta(block_model)(data)\n",
    "\n",
    "blocked_model = handlers.block(model_enumerated, hide=[\"A_star\"])\n",
    "guide_map = AutoLowRankMultivariateNormal(blocked_model)\n",
    "# guide_map = AutoDelta(blocked_model)\n",
    "\n",
    "# guide_map = AutoLowRankMultivariateNormal(model_enumerated,)\n",
    "\n",
    "# Define the AutoDelta guide\n",
    "\n",
    "# init_strategy = init_to_value(values={\"theta\": jnp.zeros(2), \"gamma\": jnp.zeros(3)})\n",
    "# guide_map = AutoDelta(model_enumerated, init_loc_fn=init_strategy)\n",
    "\n",
    "optim = ClippedAdam(0.001)\n",
    "\n",
    "# Initialize the SVI object with TraceEnum_ELBO.\n",
    "svi = SVI(model_enumerated, guide_map, optim, \n",
    "          loss=TraceEnum_ELBO(max_plate_nesting=1))\n",
    "\n",
    "# Assume data_sim is your data object with the required attributes.\n",
    "rng_key = jax.random.PRNGKey(0)\n",
    "svi_result = svi.run(rng_key, num_steps=10000, data=data_sim)\n",
    "\n",
    "# You can extract the learned parameters and monitor the ELBO:\n",
    "params = svi_result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true gamma:  [ 2.1972244 -2.1972246  0.5      ] \n",
      " loc_gamma:  [ 1.2437049  -2.1805823   0.48870432] \n",
      " true theta [-2.5  1. ] \n",
      " loc_theta:  [-2.3604188  1.016937 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"true gamma: \", GAMMA, \"\\n\",\n",
    "      \"loc_gamma: \", params[\"gamma_loc\"], \"\\n\",\n",
    "      \"true theta\", THETA, \"\\n\",\n",
    "      \"loc_theta: \", params[\"theta_loc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup:   1%|▏         | 66/4500 [01:15<2:16:07,  1.84s/it, 319 steps of size 4.09e-03. acc. prob=0.74] "
     ]
    }
   ],
   "source": [
    "\n",
    "# net_mod_kernel = NUTS(models.network_only_models_marginalized)\n",
    "# net_mod_kernel = NUTS(model_enumerated)\n",
    "\n",
    "# mcmc_net = MCMC(\n",
    "#     net_mod_kernel,\n",
    "#     num_warmup=2000,\n",
    "#     num_samples=2500,\n",
    "#     num_chains=1,\n",
    "#     # chain_method=\"parallel\",\n",
    "#     progress_bar=True,\n",
    "# )   \n",
    "\n",
    "# mcmc_net.run(rng_key, data_sim)\n",
    "\n",
    "# mcmc_net.print_summary()\n",
    "\n",
    "# mcmc_samps = mcmc_net.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data_torch = {\n",
    "    \"x_diff\": torch.tensor(np.array(data_sim.x_diff)),\n",
    "    \"x2_or\": torch.tensor(np.array(data_sim.x2_or)),\n",
    "    \"triu_obs\": torch.tensor(np.array(data_sim.triu_obs))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/10000 [00:00<10:01, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Loss: 69965.71875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 105/10000 [00:03<05:17, 31.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 - Loss: 69948.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 205/10000 [00:06<04:32, 35.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 - Loss: 67969.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 305/10000 [00:09<04:27, 36.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 - Loss: 67478.7734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 405/10000 [00:12<04:22, 36.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 - Loss: 67736.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 505/10000 [00:15<04:48, 32.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 - Loss: 67390.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 606/10000 [00:18<05:11, 30.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 - Loss: 67246.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 706/10000 [00:22<04:42, 32.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700 - Loss: 67075.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 803/10000 [00:25<04:38, 33.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800 - Loss: 67086.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 905/10000 [00:28<04:11, 36.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 900 - Loss: 67046.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1007/10000 [00:32<05:09, 29.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 - Loss: 67020.984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1104/10000 [00:35<05:13, 28.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1100 - Loss: 66963.109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1204/10000 [00:39<05:30, 26.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1200 - Loss: 66987.796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1307/10000 [00:42<04:10, 34.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1300 - Loss: 66988.4609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1405/10000 [00:46<04:35, 31.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1400 - Loss: 67166.9453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1506/10000 [00:49<05:19, 26.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1500 - Loss: 66937.3359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1606/10000 [00:53<04:32, 30.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600 - Loss: 66907.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1704/10000 [00:56<05:00, 27.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1700 - Loss: 66967.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1806/10000 [01:01<05:10, 26.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1800 - Loss: 66888.3671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1908/10000 [01:04<03:44, 35.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1900 - Loss: 66965.7421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2004/10000 [01:07<04:04, 32.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000 - Loss: 66858.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2104/10000 [01:10<03:50, 34.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2100 - Loss: 66854.1484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2206/10000 [01:14<04:49, 26.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2200 - Loss: 66886.1640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2307/10000 [01:18<03:54, 32.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2300 - Loss: 66849.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2403/10000 [01:21<05:07, 24.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2400 - Loss: 66833.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2507/10000 [01:25<03:34, 34.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500 - Loss: 66830.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2605/10000 [01:28<03:54, 31.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2600 - Loss: 66866.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2707/10000 [01:32<03:51, 31.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2700 - Loss: 66826.3359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2807/10000 [01:35<03:43, 32.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2800 - Loss: 66830.7578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2907/10000 [01:38<03:24, 34.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2900 - Loss: 66826.8203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3007/10000 [01:41<03:17, 35.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3000 - Loss: 66824.3203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3103/10000 [01:45<05:52, 19.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3100 - Loss: 66820.5234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3205/10000 [01:50<04:21, 26.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3200 - Loss: 66830.3359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3307/10000 [01:54<04:11, 26.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3300 - Loss: 66831.3359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3403/10000 [01:59<04:27, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3400 - Loss: 66815.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3503/10000 [02:04<03:51, 28.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3500 - Loss: 66818.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3605/10000 [02:08<03:34, 29.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3600 - Loss: 66822.9453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3703/10000 [02:11<03:23, 30.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3700 - Loss: 66814.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3804/10000 [02:15<03:23, 30.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3800 - Loss: 66821.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3906/10000 [02:18<03:19, 30.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3900 - Loss: 66824.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4005/10000 [02:22<03:26, 28.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4000 - Loss: 66822.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4105/10000 [02:25<03:14, 30.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4100 - Loss: 66813.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4203/10000 [02:29<03:10, 30.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4200 - Loss: 66818.421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4306/10000 [02:34<03:15, 29.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4300 - Loss: 66808.7890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4404/10000 [02:37<03:37, 25.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4400 - Loss: 66807.9453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4505/10000 [02:41<03:00, 30.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4500 - Loss: 66814.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4605/10000 [02:45<04:01, 22.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4600 - Loss: 66808.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4703/10000 [02:49<03:09, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4700 - Loss: 66808.921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4807/10000 [02:54<02:59, 28.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4800 - Loss: 66808.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4906/10000 [02:58<03:15, 26.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4900 - Loss: 66806.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5007/10000 [03:01<02:57, 28.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5000 - Loss: 66809.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5104/10000 [03:05<02:58, 27.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5100 - Loss: 66804.2890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5207/10000 [03:10<02:44, 29.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5200 - Loss: 66809.4609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5306/10000 [03:13<02:42, 28.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5300 - Loss: 66812.9921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5405/10000 [03:17<02:44, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5400 - Loss: 66805.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5503/10000 [03:21<04:09, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5500 - Loss: 66805.2890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5604/10000 [03:29<06:27, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5600 - Loss: 66804.9453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5705/10000 [03:33<03:04, 23.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5700 - Loss: 66803.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5806/10000 [03:36<02:13, 31.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5800 - Loss: 66803.3515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5906/10000 [03:40<02:05, 32.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5900 - Loss: 66805.0546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6005/10000 [03:43<02:20, 28.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6000 - Loss: 66805.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6107/10000 [03:46<01:59, 32.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6100 - Loss: 66804.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 6207/10000 [03:49<01:53, 33.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6200 - Loss: 66800.6953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6307/10000 [03:52<01:42, 36.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6300 - Loss: 66808.2109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 6407/10000 [03:55<01:41, 35.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6400 - Loss: 66803.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6505/10000 [03:59<02:05, 27.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6500 - Loss: 66803.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6603/10000 [04:02<01:43, 32.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6600 - Loss: 66802.3515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6706/10000 [04:05<01:37, 33.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6700 - Loss: 66802.1171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6806/10000 [04:08<01:33, 34.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6800 - Loss: 66803.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6905/10000 [04:11<01:47, 28.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6900 - Loss: 66800.953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7006/10000 [04:15<01:23, 35.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7000 - Loss: 66801.1953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7106/10000 [04:17<01:18, 37.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7100 - Loss: 66798.8203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 7206/10000 [04:20<01:19, 35.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7200 - Loss: 66800.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7302/10000 [04:23<01:20, 33.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7300 - Loss: 66800.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7406/10000 [04:26<01:12, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7400 - Loss: 66800.6015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7506/10000 [04:29<01:10, 35.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7500 - Loss: 66801.3515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7606/10000 [04:32<01:03, 37.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7600 - Loss: 66800.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7706/10000 [04:35<01:13, 31.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7700 - Loss: 66805.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7806/10000 [04:38<01:07, 32.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7800 - Loss: 66801.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7906/10000 [04:41<00:56, 37.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7900 - Loss: 66800.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8006/10000 [04:44<00:59, 33.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8000 - Loss: 66805.2265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8106/10000 [04:47<00:53, 35.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8100 - Loss: 66802.171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8206/10000 [04:50<00:59, 30.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8200 - Loss: 66799.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8306/10000 [04:53<00:58, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8300 - Loss: 66800.3046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8408/10000 [04:56<00:44, 35.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8400 - Loss: 66796.09375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 8504/10000 [04:59<00:43, 34.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8500 - Loss: 66804.4296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8608/10000 [05:02<00:38, 36.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8600 - Loss: 66796.7421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8708/10000 [05:05<00:36, 35.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8700 - Loss: 66802.3046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8804/10000 [05:08<00:34, 34.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8800 - Loss: 66796.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8907/10000 [05:11<00:31, 35.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8900 - Loss: 66798.3984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9007/10000 [05:14<00:29, 33.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9000 - Loss: 66797.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9107/10000 [05:17<00:25, 34.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9100 - Loss: 66795.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9207/10000 [05:20<00:26, 30.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9200 - Loss: 66799.4140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9307/10000 [05:23<00:21, 31.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9300 - Loss: 66796.796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9404/10000 [05:26<00:17, 34.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9400 - Loss: 66797.03125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 9507/10000 [05:29<00:15, 32.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9500 - Loss: 66796.453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9604/10000 [05:32<00:12, 32.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9600 - Loss: 66800.2890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9706/10000 [05:35<00:08, 34.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9700 - Loss: 66800.7578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9805/10000 [05:39<00:06, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9800 - Loss: 66796.421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9907/10000 [05:42<00:02, 32.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9900 - Loss: 66795.7734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [05:45<00:00, 28.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "from tqdm import tqdm\n",
    "\n",
    "@pyro.infer.config_enumerate\n",
    "def pyro_noisy_networks_model(data):\n",
    "    \"\"\"\n",
    "    Network model for one noisy observed network. True network is geenrated from LSM.\n",
    "    :param x: pairwise x-differences\n",
    "    :param x2: pariwise x2-equality\n",
    "    :param triu_v: observed triu values (upper triangular)\n",
    "    :param N: number of units\n",
    "    :param K: latent variables dimension\n",
    "    \"\"\"\n",
    "\n",
    "    with pyro.plate(\"theta_dim\", 2):\n",
    "        theta = pyro.sample(\"theta\", pyro.distributions.Normal(0, 5))\n",
    "        # theta = pyro.sample(\"theta\", pyro.distributions.StudentT(df=5, loc=0, scale=2))\n",
    "\n",
    "    mu_net = theta[0] + theta[1]*data[\"x2_or\"]\n",
    "    mu_net = torch.clamp(mu_net, min=-30, max=30)\n",
    "\n",
    "    with pyro.plate(\"gamma_i\", 3):\n",
    "        gamma = pyro.sample(\"gamma\", pyro.distributions.Normal(0, 5))\n",
    "        # gamma = pyro.sample(\"gamma\", pyro.distributions.StudentT(df=5, loc=0, scale=2))\n",
    "\n",
    "    with pyro.plate(\"A* and A\", data[\"triu_obs\"].shape[0]):\n",
    "        triu_star = pyro.sample(\n",
    "            \"triu_star\",\n",
    "            pyro.distributions.Bernoulli(logits=mu_net),\n",
    "            infer={\"enumerate\": \"parallel\"},\n",
    "        )\n",
    "\n",
    "        logit_misspec = torch.where(\n",
    "            triu_star == 1.0, gamma[0], gamma[1] + gamma[2] * data[\"x_diff\"]\n",
    "        )\n",
    "\n",
    "        pyro.sample(\n",
    "            \"obs_triu\", pyro.distributions.Bernoulli(logits=logit_misspec), obs=data[\"triu_obs\"]\n",
    "        )\n",
    "\n",
    "def get_guide():\n",
    "        return pyro.infer.autoguide.AutoLowRankMultivariateNormal(\n",
    "            pyro.poutine.block(pyro_noisy_networks_model, hide=[\"triu_star\"]),\n",
    "            init_loc_fn=pyro.infer.autoguide.init_to_median(),\n",
    "        )\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "py_guide = get_guide()\n",
    "loss_fn = pyro.infer.TraceEnum_ELBO(max_plate_nesting=1)\n",
    "optimizer = pyro.optim.ClippedAdam({\"lr\": 0.001})\n",
    "svi = pyro.infer.SVI(pyro_noisy_networks_model, py_guide, optimizer, loss=loss_fn)\n",
    "\n",
    "num_steps = 10000\n",
    "losses_full = []\n",
    "for step in tqdm(range(num_steps)):\n",
    "    # svi.step(data_torch)\n",
    "    loss = svi.step(data_torch)\n",
    "    losses_full.append(loss)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step} - Loss: {loss}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true gamma:  [ 2.1972244 -2.1972246  0.5      ] \n",
      " map gamma:  tensor([-0.0290, -2.4265,  0.5974]) \n",
      " true theta [-2.5  1. ] \n",
      " map theta:  tensor([-1.3854,  1.0348])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = py_guide.median()\n",
    "\n",
    "print(\"true gamma: \", GAMMA, \"\\n\",\n",
    "        \"map gamma: \", params[\"gamma\"], \"\\n\",\n",
    "        \"true theta\", THETA, \"\\n\",\n",
    "        \"map theta: \", params[\"theta\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
